
# Hate Speech Detection

A hate speech detection model using Bidirectional LSTM to classify types of hates detected in the text provided by user in real-time.

Accuracy achieved by this model is 98.80 %.

The dataset used is Toxic Comment Classification Challenge from Kaggle.

Currently the project's backend is not deployed online but in order to run the project and visualize hate speech detection results, follow the below steps:

    1. Download the code zip file or perform Git Clone
    2. Open cmd and run this command to setup the backend: 'python app.py'
    3. Go live to analyze the hate speech detection results in real-time

This project is the result of our Senior Design Project in Institute of Technical Education and Research, Bhubaneswar, India.
## Authors

- [@Abhilasha6](https://github.com/Abhilasha6)
- [@Abhijeet-Anand-01](https://github.com/Abhijeet-Anand-01)
- [@Arnav6475226](https://github.com/Arnav6475226)
- [@Anushkadas07](https://github.com/Anushkadas07)